{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metrics(Y_pred, Y_test, X_test):\n",
    "    score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "    count = 0\n",
    "    tn = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    l = 0\n",
    "    for i in range(len(Y_pred)):\n",
    "        pl = Y_pred[i]\n",
    "        tl = Y_test[i]\n",
    "        if(tl[0]==1.0):\n",
    "            l = 0\n",
    "        else:\n",
    "            l = 1\n",
    "        if(l==pl):\n",
    "            count = count+1\n",
    "            if(pl==1):\n",
    "                tp = tp+1\n",
    "            else:\n",
    "                tn = tn+1\n",
    "        else:\n",
    "            if(l==1):\n",
    "                fn = fn+1\n",
    "            else:\n",
    "                fp = fp+1\n",
    "    print(\"Test score: \", score[0])\n",
    "    print(\"Test accuracy: \", score[1])\n",
    "    print(\"Correctly classified images: \",count)\n",
    "    print(\"True Negatives: \", tn)\n",
    "    print(\"True Positives: \", tp)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \",fn)\n",
    "    print(\"Precision: \",tp/(tp+fp))\n",
    "    print('Recall: ',tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data\n",
    "\n",
    "def load_data():\n",
    "    # load train folder\n",
    "    train_path = os.getcwd()+'/train'\n",
    "    train_images = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    train_name = []\n",
    "    for image in train_images:\n",
    "        #load image and add it to a list -- X_train\n",
    "        img = cv2.imread(train_path+'/'+image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        X_train.append(img)\n",
    "        \n",
    "        #also add its label to another list -- Y_train\n",
    "        if 'not' in image:\n",
    "            Y_train.append(0)\n",
    "        else:\n",
    "            Y_train.append(1)\n",
    "            \n",
    "        #add its name to another list -- train_name\n",
    "        train_name.append(image)\n",
    "        \n",
    "    tuple1 = (X_train, Y_train, train_name)\n",
    "    \n",
    "    test_path = os.getcwd()+'/test'\n",
    "    test_images = [f for f in listdir(test_path) if isfile(join(test_path,f))]\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    test_name = []\n",
    "    for image in test_images:\n",
    "        #load image and add it to a list -- X_test\n",
    "        img = cv2.imread(test_path+'/'+image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        X_test.append(img)\n",
    "        \n",
    "        #also add its label to another list -- Y_test\n",
    "        if 'not' in image:\n",
    "            Y_test.append(0)\n",
    "        else:\n",
    "            Y_test.append(1)\n",
    "        \n",
    "        #add its name to another list -- test_name\n",
    "        test_name.append(image)\n",
    "        \n",
    "    tuple2 = (X_test, Y_test, test_name)\n",
    "    \n",
    "    return tuple1, tuple2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(20, kernel_size=5, padding='same', input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        \n",
    "        #Flatten => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        #a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network and Training\n",
    "\n",
    "NB_EPOCH = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT = 0.2\n",
    "IMG_ROWS, IMG_COLS = 64, 64\n",
    "NB_CLASSES = 2\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train_samples\n",
      "469 test samples\n"
     ]
    }
   ],
   "source": [
    "#data shuffled and split between train and test set\n",
    "\n",
    "a,b = load_data()\n",
    "X_train = np.array(a[0])\n",
    "Y_train = np.array(a[1])\n",
    "X_test = np.array(b[0])\n",
    "Y_test = np.array(b[1])\n",
    "# (X_train, Y_train), (X_test, Y_test) = load_data()\n",
    "k.set_image_dim_ordering(\"th\")\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#we need 60K * [1*28*28] shape as input to the CONVNET\n",
    "X_train = X_train[:,np.newaxis,:,:]\n",
    "X_test = X_test[:,np.newaxis,:,:]\n",
    "print(X_train.shape[0], 'train_samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, padding=\"same\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 27s 34ms/step - loss: 1.0168 - acc: 0.4875 - val_loss: 0.6686 - val_acc: 0.6450\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.6770 - acc: 0.6100 - val_loss: 0.6797 - val_acc: 0.4300\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 33s 42ms/step - loss: 0.6296 - acc: 0.7925 - val_loss: 0.5563 - val_acc: 0.8650\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 28s 35ms/step - loss: 0.5387 - acc: 0.8300 - val_loss: 0.4051 - val_acc: 0.8650\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.3783 - acc: 0.8925 - val_loss: 0.3270 - val_acc: 0.8850\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2465 - acc: 0.9150 - val_loss: 0.1390 - val_acc: 0.9600\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 0.1525 - acc: 0.9500 - val_loss: 0.0946 - val_acc: 0.9650\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 24s 31ms/step - loss: 0.1183 - acc: 0.9587 - val_loss: 0.1360 - val_acc: 0.9500\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.1144 - acc: 0.9575 - val_loss: 0.0838 - val_acc: 0.9700\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.0930 - acc: 0.9688 - val_loss: 0.0759 - val_acc: 0.9700\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 27s 33ms/step - loss: 0.0763 - acc: 0.9800 - val_loss: 0.0663 - val_acc: 0.9750\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.0601 - acc: 0.9788 - val_loss: 0.0693 - val_acc: 0.9700\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0624 - val_acc: 0.9800\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 24s 29ms/step - loss: 0.0473 - acc: 0.9862 - val_loss: 0.0599 - val_acc: 0.9800\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0424 - acc: 0.9913 - val_loss: 0.0788 - val_acc: 0.9800\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0416 - acc: 0.9888 - val_loss: 0.0724 - val_acc: 0.9700\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 0.0332 - acc: 0.9937 - val_loss: 0.0697 - val_acc: 0.9700\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.0309 - acc: 0.9925 - val_loss: 0.0793 - val_acc: 0.9700\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.0261 - acc: 0.9925 - val_loss: 0.0754 - val_acc: 0.9700\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.0235 - acc: 0.9950 - val_loss: 0.0715 - val_acc: 0.9700\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.0727 - val_acc: 0.9700\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.0169 - acc: 0.9962 - val_loss: 0.0755 - val_acc: 0.9700\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.0152 - acc: 0.9962 - val_loss: 0.0756 - val_acc: 0.9700\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.0796 - val_acc: 0.9800\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 24s 29ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0791 - val_acc: 0.9650\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0114 - acc: 0.9975 - val_loss: 0.1143 - val_acc: 0.9550\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0870 - val_acc: 0.9700\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0112 - acc: 0.9988 - val_loss: 0.1516 - val_acc: 0.9450\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9650\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.1507 - val_acc: 0.9450\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0102 - acc: 0.9975 - val_loss: 0.0862 - val_acc: 0.9650\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.1088 - val_acc: 0.9700\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0983 - val_acc: 0.9650\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9750\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9750\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9650\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9700\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9750\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9600\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9750\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 0.9750\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 9.9083e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9700\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 8.9395e-04 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9700\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 8.4705e-04 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9700\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 7.8463e-04 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9700\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 7.4110e-04 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9700\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 6.8954e-04 - acc: 1.0000 - val_loss: 0.1221 - val_acc: 0.9700\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 6.5202e-04 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9700\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 6.1384e-04 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9700\n",
      "Epoch 50/50\n",
      "768/800 [===========================>..] - ETA: 0s - loss: 5.7568e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "#Initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 7s 14ms/step\n",
      "Test score:  0.358504069854132\n",
      "Test accuracy:  0.9275053307445827\n",
      "Correctly classified images:  435\n",
      "True Negatives:  211\n",
      "True Positives:  224\n",
      "False Positives:  19\n",
      "False Negatives:  15\n",
      "Precision:  0.9218106995884774\n",
      "Recall:  0.9372384937238494\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_classes(X_test)\n",
    "accuracy_metrics(Y_pred, Y_test, X_test)\n",
    "model.save('model_v0_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
