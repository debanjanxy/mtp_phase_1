{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metrics(Y_pred, Y_test, X_test):\n",
    "    score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "    count = 0\n",
    "    tn = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    l = 0\n",
    "    for i in range(len(Y_pred)):\n",
    "        pl = Y_pred[i]\n",
    "        tl = Y_test[i]\n",
    "        if(tl[0]==1.0):\n",
    "            l = 0\n",
    "        else:\n",
    "            l = 1\n",
    "        if(l==pl):\n",
    "            count = count+1\n",
    "            if(pl==1):\n",
    "                tp = tp+1\n",
    "            else:\n",
    "                tn = tn+1\n",
    "        else:\n",
    "            if(l==1):\n",
    "                fn = fn+1\n",
    "            else:\n",
    "                fp = fp+1\n",
    "    print(\"Test score: \", score[0])\n",
    "    print(\"Test accuracy: \", score[1])\n",
    "    print(\"Correctly classified images: \",count)\n",
    "    print(\"True Negatives: \", tn)\n",
    "    print(\"True Positives: \", tp)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \",fn)\n",
    "    print(\"Precision: \",tp/(tp+fp))\n",
    "    print('Recall: ',tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data\n",
    "\n",
    "def load_data():\n",
    "    # load train folder\n",
    "    train_path = os.getcwd()+'/train'\n",
    "    train_images = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    train_name = []\n",
    "    for image in train_images:\n",
    "        #load image and add it to a list -- X_train\n",
    "        img = cv2.imread(train_path+'/'+image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        X_train.append(img)\n",
    "        \n",
    "        #also add its label to another list -- Y_train\n",
    "        if 'not' in image:\n",
    "            Y_train.append(0)\n",
    "        else:\n",
    "            Y_train.append(1)\n",
    "            \n",
    "        #add its name to another list -- train_name\n",
    "        train_name.append(image)\n",
    "        \n",
    "    tuple1 = (X_train, Y_train, train_name)\n",
    "    \n",
    "    test_path = os.getcwd()+'/test'\n",
    "    test_images = [f for f in listdir(test_path) if isfile(join(test_path,f))]\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    test_name = []\n",
    "    for image in test_images:\n",
    "        #load image and add it to a list -- X_test\n",
    "        img = cv2.imread(test_path+'/'+image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        X_test.append(img)\n",
    "        \n",
    "        #also add its label to another list -- Y_test\n",
    "        if 'not' in image:\n",
    "            Y_test.append(0)\n",
    "        else:\n",
    "            Y_test.append(1)\n",
    "        \n",
    "        #add its name to another list -- test_name\n",
    "        test_name.append(image)\n",
    "        \n",
    "    tuple2 = (X_test, Y_test, test_name)\n",
    "    \n",
    "    return tuple1, tuple2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(20, kernel_size=5, padding='same', input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        \n",
    "        #Flatten => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        #a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network and Training\n",
    "\n",
    "NB_EPOCH = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT = 0.2\n",
    "IMG_ROWS, IMG_COLS = 64, 64\n",
    "NB_CLASSES = 2\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train_samples\n",
      "469 test samples\n"
     ]
    }
   ],
   "source": [
    "#data shuffled and split between train and test set\n",
    "\n",
    "a,b = load_data()\n",
    "X_train = np.array(a[0])\n",
    "Y_train = np.array(a[1])\n",
    "X_test = np.array(b[0])\n",
    "Y_test = np.array(b[1])\n",
    "# (X_train, Y_train), (X_test, Y_test) = load_data()\n",
    "k.set_image_dim_ordering(\"th\")\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#we need 60K * [1*28*28] shape as input to the CONVNET\n",
    "X_train = X_train[:,np.newaxis,:,:]\n",
    "X_test = X_test[:,np.newaxis,:,:]\n",
    "print(X_train.shape[0], 'train_samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, padding=\"same\", kernel_size=5)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 28s 35ms/step - loss: 0.9770 - acc: 0.4925 - val_loss: 0.7069 - val_acc: 0.4400\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.6876 - acc: 0.5150 - val_loss: 0.6857 - val_acc: 0.4400\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.6702 - acc: 0.5200 - val_loss: 0.6390 - val_acc: 0.7500\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.5668 - acc: 0.8125 - val_loss: 0.4457 - val_acc: 0.9000\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.2835 - acc: 0.9513 - val_loss: 0.2540 - val_acc: 0.9050\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.1496 - acc: 0.9487 - val_loss: 0.1773 - val_acc: 0.9650\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0844 - acc: 0.9725 - val_loss: 0.1692 - val_acc: 0.9650\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0583 - acc: 0.9800 - val_loss: 0.1932 - val_acc: 0.9650\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0439 - acc: 0.9850 - val_loss: 0.2086 - val_acc: 0.9500\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0355 - acc: 0.9875 - val_loss: 0.2018 - val_acc: 0.9500\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0259 - acc: 0.9913 - val_loss: 0.2189 - val_acc: 0.9450\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.2100 - val_acc: 0.9450\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.2141 - val_acc: 0.9500\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.2599 - val_acc: 0.9550\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0230 - acc: 0.9937 - val_loss: 0.2533 - val_acc: 0.9450\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0204 - acc: 0.9925 - val_loss: 0.2513 - val_acc: 0.9450\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0153 - acc: 0.9900 - val_loss: 0.2675 - val_acc: 0.9550\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.2428 - val_acc: 0.9500\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 0.2591 - val_acc: 0.9500\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0097 - acc: 0.9988 - val_loss: 0.2375 - val_acc: 0.9600\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.2405 - val_acc: 0.9550\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2753 - val_acc: 0.9450\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2968 - val_acc: 0.9450\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.9450\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2985 - val_acc: 0.9450\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2944 - val_acc: 0.9450\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2974 - val_acc: 0.9450\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 9.2443e-04 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.9500\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 8.3075e-04 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.9500\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 6.9217e-04 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.9450\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 6.3177e-04 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 0.9450\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 5.6894e-04 - acc: 1.0000 - val_loss: 0.3259 - val_acc: 0.9450\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 5.3795e-04 - acc: 1.0000 - val_loss: 0.3283 - val_acc: 0.9450\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 4.7420e-04 - acc: 1.0000 - val_loss: 0.3331 - val_acc: 0.9450\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 4.1460e-04 - acc: 1.0000 - val_loss: 0.3363 - val_acc: 0.9450\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 3.8026e-04 - acc: 1.0000 - val_loss: 0.3392 - val_acc: 0.9450\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 3.4995e-04 - acc: 1.0000 - val_loss: 0.3411 - val_acc: 0.9450\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 3.2846e-04 - acc: 1.0000 - val_loss: 0.3428 - val_acc: 0.9450\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 3.1106e-04 - acc: 1.0000 - val_loss: 0.3439 - val_acc: 0.9450\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.8672e-04 - acc: 1.0000 - val_loss: 0.3455 - val_acc: 0.9450\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.6817e-04 - acc: 1.0000 - val_loss: 0.3472 - val_acc: 0.9450\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.5447e-04 - acc: 1.0000 - val_loss: 0.3492 - val_acc: 0.9450\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.3784e-04 - acc: 1.0000 - val_loss: 0.3514 - val_acc: 0.9450\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.2739e-04 - acc: 1.0000 - val_loss: 0.3531 - val_acc: 0.9450\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 2.1520e-04 - acc: 1.0000 - val_loss: 0.3550 - val_acc: 0.9450\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 34s 42ms/step - loss: 2.0296e-04 - acc: 1.0000 - val_loss: 0.3583 - val_acc: 0.9450\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 28s 35ms/step - loss: 1.9520e-04 - acc: 1.0000 - val_loss: 0.3602 - val_acc: 0.9450\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 1.8901e-04 - acc: 1.0000 - val_loss: 0.3609 - val_acc: 0.9450\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 27s 34ms/step - loss: 1.7628e-04 - acc: 1.0000 - val_loss: 0.3605 - val_acc: 0.9450\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 1.6721e-04 - acc: 1.0000 - val_loss: 0.3608 - val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "#Initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 7s 14ms/step\n",
      "Test score:  0.358504069854132\n",
      "Test accuracy:  0.9275053307445827\n",
      "Correctly classified images:  435\n",
      "True Negatives:  211\n",
      "True Positives:  224\n",
      "False Positives:  19\n",
      "False Negatives:  15\n",
      "Precision:  0.9218106995884774\n",
      "Recall:  0.9372384937238494\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_classes(X_test)\n",
    "accuracy_metrics(Y_pred, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
